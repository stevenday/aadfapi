# AADF Api

An API for Devon's AADF data from the DfT for 2000 -> 2015.

## Using the API
The API is built using Django Rest Framework, which serves a browsable HTML
representation of the API as well as GeoJSON. The live version is hosted on
Heroku at: https://shielded-journey-29144.herokuapp.com, using their
experimental support for geospatial libraries. Since it's only using their
free hosting tier, it is a little slow, but I've paginated the api in order to
make the response times tolerable.

If you visit [the api](https://shielded-journey-29144.herokuapp.com) in a
browser, you'll see a list of the available endpoints. Clicking on either one
of them will show you their results in an HTML page (containing formatted
json). There are pagination and filtering options on the page too, so it
should be fairly self-explanatory. However, here's a summary of the endpoints
and their options just in case:

### `GET /counts/`
Provides a paginated list of all the AADF counts in Devon. Returns a GeoJSON
`FeatureCollection` under the results key, with each feature in the being one
AADF count for a specific year and count point. There are 100 counts per page.

You can specify the following query parameter to filter the results:

- `page`: An integer page number
- `road`: A string road name (e.g. "M5", note they are case-sensitive). This
  will return all of the counts on that road.
- `year`: An integer year between 2000 and 2015. This will return all of the
  counts in that year.
- `count_point_id`: An integer count point id from the DfT. This will return all
  of the counts for the given count point.
- `ward__wd16cd`: A string GSS code for a ward. This will return all of the
  counts geographically contained within that ward, based on the count point
  location.

### `GET /counts/:id`
Get a specific count from its numeric id number. Returns a GeoJSON `Point`
`Feature` object as the top-level element.

### `GET /wards/`
Provides a paginated list of all the uk wards. Returns a GeoJSON
`FeatureCollection` under the `results` key with each feature in the
collection being one ward, though note ward boundaries may contain multiple
polygons. There are 10 wards per page.

You can specify the following query parameter to filter the results:

- `page`: An integer page number

### `GET /wards/:id`
Get a specific ward from its numeric id number. Note this is the internal id
number, not the GSS code or `objectid`. Returns a GeoJSON `MultiPolygon`
`Feature` object as the top-level element.

## Code/Project structure
The code is hopefully fairly standard Django 1.11 project - project-level
stuff like settings and the top-level route/url definitions live in `/aadf`,
whilst I've extracted the data models, and api-specific code to what Django
calls an "app" in `/api`. This is basically a separate, re-usable python
module. Because I've used Django Rest Framework (DRF) to provide the api, it's
slightly non-standard Django code, but it's still basically MVC-based. The
models are in `models.py`, `ViewSets` (defined in `urls.py` for now) are the
controllers and the "views" are auto-generated by DRF.

`/config` contains code mostly related to setting up the vagrant box, then
there are dotfiles and other standard python & Heroku project files in the root
directory.

## Local installation
I've included a Vagrantfile which should set up a fully working local copy of
the api. To start it, simply `cd` into the git repo directory and type
`vagrant up && vagrant ssh`. It will take a while (go make a cup of tea) and
please note it will try to allocate 2G of ram, but should set up all of the
dependecies and load all of the data for you. If you're not using virtualbox
to provide virtual machines to vagrant, you might have to up the ram in
whatever way your provider allows, because loading in the spatial data takes
a lot of memory, so it will probably fail on the default setting.

This is based mostly on https://github.com/philgyford/vagrant-heroku-cedar-14-python
but with a few modifications to make it more up to date and match heroku's
current cedar-14 stack more closely. I also added a little bit extra to the
setup to load the AADF and ward data during provisioning. You can see the
changes I made more clearly
[on github](https://github.com/philgyford/vagrant-heroku-cedar-14-python/pull/6)
because I opened a pull request afterwards to share them back.

### Starting the server
Once you're inside the vagrant VM, `cd` to `/vagrant` and type
`python manage.py runserver 0.0.0.0:5000` to start the development server.
This should now be accessible in your browser from [http://localhost:5000](http://localhost:5000)

### Running the tests
Run `python manage.py test` from `/vagrant` inside the VM to run the tests.

## Notes/Thoughts
I initially sought to model the data in a more normalised way, splitting out
`Road`, `RoadCategory`, `EstimationMethod` and `CountPoint` models, but I then
realised that the data is not particularly well suited to that, because things
change every year. For example, there are count points that move location, or
change which junction they start or end at, and roads which are re-categorised
year-on-year. In order to get something done quickly, I decided to just dump
everything into one table instead.

I'm aware how fickle the support for GDAL/GEOS/PROJ4 is and the dependency
hell that can ensue when trying to install it, so I provided a vagrantfile to
try to limit any compatibility issues when running the code locally. I've
only tested the code under this environment (and on heroku which it's supposed
to mimic). There might be some issues with other versions of the geospatial
libraries, or versions of python other than 3.6.

I would normally write better tests than these, obviously making them more
extensive if this was going to stick around, but also making sure they don't
need to access the internet whilst running, and that they run more quickly by
operating on some trimmed-down fixture files. I'd probably use the
[responses](https://github.com/getsentry/responses) library to mock out the
url calls and return a fixture if I had a bit more time. I'd also break up the
great big test methods into smaller chunks, ideally so that there's a
single-assertion per method. Finally, I'd set up some better test data using
something like [FactoryBoy](https://github.com/FactoryBoy/factory_boy).

I went with Django and Django Rest Framework because I'd worked with it before
and knew that the support for geospatial stuff was good. The rest framework
pieces that I've used are very basic, and it's not really best practice to
just dump everything in `urls.py`, but since I was approaching this as a
prototype, I figured it was good enough for now. Rest framework does provide
a great platform for growing a solid api, but it might also be overkill for a
small project like this in production.
